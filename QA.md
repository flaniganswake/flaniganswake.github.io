## Random Q&A



__What are your thoughts on stored procedures?__

Stored procedures are very useful for a number of reasons. They encapsulate common tasks that would be difficult to regenerate. They are written once - then used as modular, defined tasks which can be implemented by many users. Since they are designed to modify data via CRUD applications avoiding security vulnerabilities, mistakes and errors are very important considerations. They can also be tweaked and improved when necessary. But they do present challenges because they can be difficult to develop and maintain. They should be primarily be used for common, bounded queries - not complex or flexible solutions.

__Discuss the GIL and its implications__ 

The Global Interpreter Lock was implemented in Python to make the growing number of C extensions thread-safe. Python became much more useful with the addition of C extensions - especially with CPU intensive operations. But since the GIL is not necessary outside of the interpreter - I/O bound operations can release the the GIL explicitly greatly increasing performance. Otherwise it can become a bottleneck. The Python interpreter uses the GIL when executing bytecode - so this happens quite often. It acts under the assumption that no CPython between bytecodes can be considered thread-safe - so the lock is acquired by default. Since the GIL is handed-off periodically between threads true multitasking is impossible.

__What are your thoughts on multiple inheritance?__

Multiple inheritance in OOP makes it easier to compose classes from small,
well-defined mixin base classes. It works best when the functionality of the base classes is clearly modular and independent. It follows the paradigm of ‘only write once’. But it can become confusing with conflicting function names within the subclasses. As an example - I designed and built a distributed computing system which used multiple inheritance extensively. Within the system there were necessary tasks which needed to be implemented quite often. I used a few base classes which handled all the system calls without explicit interaction with the computation level. The subclasses interacted with the base classes through callback events. This allowed fairly independent, uncoupled development of the classes. One of the cons of multiple inheritance is that it is often forced and leads to semantic ambiguity. It should only be used if it extends an object’s functionality and in general - makes sense.

__What have you found are the hardest things about code maintainability?__

Code maintainability becomes difficult if the design is brittle, heavily coupled, obfuscated or generally hard to understand. And unfortunately - these are all too common. Even if I personally wrote the code - eventually I will not recall the reasons I made certain design decisions. So the code not only needs to be well documented, but refactored so that it makes sense. This includes meaningful variable names, tight yet extensible class designs and only essential code in the code base. Unused code is confusing and invites problems. If blocks are commented out - it may be assumed that they work, but some feature was changed. They can be inadvertently added back in without knowing the results. Here are some keys to success that I’ve found. Don’t make too many assumptions within the code. And if you do - make it clear what they are. Conditions and needs always change. When building the code always keep in mind how easy it would be to debug. Everything is breakable. Dependencies should be minimized and the scope should be tight. Keep issues localized as much as possible. Refactoring well is crucial. Clarity, flexibility and iterative testing should always be in forefront.

__How do you think about concurrency vs. parallelism? In what situations would you be thinking of one vs. the other?__

Concurrency is about threading and context switching. Communication between threads requires locks and semaphores to maintain boundary integrity. On the other hand - parallelism is multi-processing where the computations can be performed independently with little or no interaction. Here we can use multiple CPUs with relatively linear speedups. The distributed computing system I built used applications which highlighted tightly coupled vs embarrassingly parallel scenarios. The three primary applications were ray-tracing, travelling salesman and cellular automation. The POV-Ray app was easily chunked by file segments - so it was a great example of linear parallelism. The brute force Traveling Salesman app was actually super-linear since the workers occasionally updated each other as new minimum paths were discovered. These two did not gain much performance locally as worker threads on a single CPU - but exhibited huge gains when run on 50 machines. Conway’s Game of life on a cube was a great example of the pitfalls of frequent communication. With each iteration the faces would update their boundary states. When the faces ran as separate processes the computational needs were so minimal - that the parallelism became paralyzed. Especially when run over a network. The app ran much faster with local threads. Choosing concurrency or parallelism is dependent upon computational complexity, the
ease of chunking the data and the extent of interleaving the processes.

__Give some brief thoughts on object-oriented programming and alternatives to it.__

In my opinion - object-oriented programming is often overused. It’s not appropriate for all applications. It can be overkill and can eat up memory when it’s not necessary to do so. However, its benefits include being able to encapsulate mutable state, exposing interfaces to interact with that state and providing a bound pattern of extensible functionality. I find that OOP should be used when object modelling makes sense. This becomes apparent with interactive applications which expose methods for managing state. OOP should also be used if an application has become complex enough to benefit from encapsulation, inheritance, polymorphism and abstraction. If flow and speed are the most important issues OOP is not the best choice. Multi-paradigm languages offer other approaches which have their inherent strengths - primarily procedural and functional. Functional coding manipulates immutable, stateless data. It is appropriate for computationally complex code which has well-defined inputs and outputs without unforeseen side effects. I’ve found that procedural is a good starting point in design which may lead to OOP when it becomes apparent that modularity and state management is the best approach. This is often the case as the code base grows because it adds clarity and flexibility.

__In your opinion, what’s the most important trend happening in cloud computing today__

I believe the most important trend in cloud computing has been the movement towards the use of container systems. These include Docker, Snap, ECS, Kubernetes and Azure services. These OS system virtualizations are the latest, natural step towards code modularization, reduced dependencies, decoupling, higher security and transparent development and deployment. Containers have reduced code maintenance, improved consistency, runtime isolation and eased CI/CD pipelines. With containerization we now have the ability to deploy code modules/apps quickly and ubiquitously. This has resulted in impressive leaps in flexibility and accessibility for tailor-made configurations for max efficiency and speed. It’s now possible to deploy complex code on clusters with GPUs that would typically run on a supercomputer. There is currently an abundance of user options for horizontal and vertical scaling due to diverse hardware and configuration schemes. Containers allow predictable, isolated code to be run as well-designed, readily available and secure components.

__How do you approach testing?__

Testing is an ongoing process - even after the code is in production. Testing not only reveals errors; it also reveals short-sighted assumptions and areas in need of improvement. Testing should include unit testing, client usage and deployment in an environment that strictly mimics production. Also it is very helpful to allow people unfamiliar with the code to perform testing. When the original coder or a designated tester run through sequences - they tend to only check well-worn paths and scripted series of tests. The goal is complete coverage. Also value any feedback as an indication that a feature can be more intuitive or less prone to mistakes. When I built user interfaces for the warehouse merchandising station at Swap.com I had certain goals that needed to be met. I wanted clarity, speed, intuitive steps and an ability to reset selections or cancel and start over without any remnants. The task was to process an inbound item of clothing by recording its category, condition, style, type, size, color and brand. The touchscreen UI built the selection boxes dynamically based upon a backend properties tree. Testing on the floor revealed a few wrong paths, supplying the server with bad data. Obviously it was not feasible to test all possible cases before deployment. Also the incredible speed of the associates making selections with the UI was not expected. I found that there were many instances where caching could be used to avoid extensive network bandwidth and latency. In other words - I have always used testing as a process. Errors are typically easy to fix when they are obvious. Some are more subtle. Some take a period of time to detect. But testing should also be used to improve the code - tweaking it appropriately to make it more useful and intuitive.

__How do you approach security?__

Application security should be addressed as early in the development process as possible. Security has become a much larger concern due to the advent of continuous deployment and integration. And the increased exposure of interfaces and services has invited the probability of even more intrusions - especially with the rise of automated attacks. Damage can be done much sooner than expected. When I worked at NCSA as a security engineer I developed a number of intrusion sensors for Prelude, Snort and Bro IDSs. They primarily used network packet analysis and log file inspection. Log files typically revealed traces of attempted and successful privilege escalation. The most difficult analysis was the correlation of attacks. Many attacks revealed a succession of activities which left a familiar trace. We also set up some honeypots to trap intruders. Once attacks were detected we made network adjustments such as iptable, firewall, router and access permissions to minimize any damage. Application security can certainly be enhanced by CI/CD practices. Rapid turnaround cycles allow quicker detection and response. Common code vulnerables can be avoided such as SQL injection, compromised authentication and unprotected sensitive data with proper data validation and frequent access audits. As long as security is a critical concern, problems can be avoided or minimized.

__What software development processes have you participated in? Which do you think work well and why?__

I’ve worked with a variety of development processes to varying degrees of success. I’ve inherited huge legacy code bases which were difficult to deal with. One in particular was about 1.5 million lines of C/C++ code. My first approach is to simplify and condense the code so I could grasp what was actually being used. I put traces in the files and ended up getting rid of about half of the code. I’ve learned that if you let a code base grow and become more complex over time - it will cause huge problems. This code base in particular was built by many part-time programmers without much interest in the feature-bloated monster they had created. This is obviously pre-agile days. With a good foundation and sound CI/CD practices this can and should be avoided. I once managed a group whose direction was driven solely by the CEO through late night phone calls. I came in and focused the development in the short and long term. I relied on weekly and monthly task lists that allowed coders to work on what they enjoyed and what they excelled at. And no more phone calls. This worked out very well - but it was a struggle. My most recent position was a great example of an ideal agile environment. I was responsible for all of the software used in the warehouse. We ran the the website and warehouse on the same GAE production code - which became a big problem with deployments. Especially since the rest of the dev team was in Helsinki. So I had to handle my development in the most efficient and dependable way possible. I worked closely with the associates on the floor presenting ideas, prototypes, iterative testing and fixing issues as they arose. It was a very cooperative effort. And it allowed me to produce some exceptional software. The associates felt a sense of ownership because of their participation. And they enjoyed working on the user interfaces they helped build. Generally - I have approached development using the following. Always keep complexity to a minimum. Build code and deploy with short, interactive, iterative, well-tested cycles. Systems should be as modularized as possible. Modules should be decomposed into a hierarchy of components - with no code duplication. If it breaks - it breaks in one place. And this keeps problem solving and development bounded and manageable. And this leads to great, extensible and reliable code.
